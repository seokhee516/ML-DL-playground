{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seokhee516/ML-DL-playground/blob/main/ai08_sc42x_%EC%A0%95%EC%84%9D%ED%9D%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy_9hARVUo9L"
      },
      "source": [
        "# SC42x \n",
        "## 자연어처리 (Natural Language Processing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dNUXHiLbBdp"
      },
      "source": [
        "# Part 1 : 개념 요약\n",
        "\n",
        "> 다음의 키워드에 대해서 **한 줄**로 간단하게 요약해주세요. (세션 노트를 참고하여도 좋습니다.)<br/>\n",
        "> **Tip : 아래 문제를 먼저 수행한 후 모델 학습 등 시간이 오래 걸리는 셀이 실행되는 동안 아래 내용을 작성하면 시간을 절약할 수 있습니다.**\n",
        "\n",
        "**N421**\n",
        "- Stopwords(불용어) : 분석을 하는 것에 있어서는 큰 도움이 되지 않는 단어들을 말합니다.\n",
        "- Stemming과 Lemmatization : Stemming이란 단어에서 어간과 접사를 분리하는 과정을 의미하고, Lemmatization이란 기본 사전형 단어 형태로 변환하는 것을 의미합니다.\n",
        "- Bag-of-Words : 단어의 빈도 수를 세어 벡터화하는 것을 말합니다.\n",
        "- TF-IDF : 특정 문서에만 등장하는 단어에 가중치를 주는 방식입니다.\n",
        "\n",
        "**N422**\n",
        "- Word2Vec : 단어를 벡터로(Word to Vector) 나타내는 방법입니다.\n",
        "- fastText : Word2Vec 방식에 철자(Character) 기반의 임베딩 방식을 더해준 새로운 임베딩 방식입니다.\n",
        "\n",
        "**N423**\n",
        "- RNN : 연속형 데이터를 처리하기 위해 고안된 순환 신경망입니다. \n",
        "- LSTM, GRU : RNN에 기울기 정보 크기를 조절하기 위한 Gate를 추가한 모델을 LSTM이라고 하고, LSTM의 간소한 버전인 GRU입니다.\n",
        "- Attention : Attention이란 인코더에 입력된 문장의 단어와 디코더가 생성하려는 단어가 연관된 정도를 나타내는 가중치입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g07_yjCgbBdp"
      },
      "source": [
        "# Part 2 : Fake/Real News Dataset\n",
        "\n",
        "한 주간 자연어처리 기법을 배우면서 여러분은 다양한 기술들을 접했습니다.<br/>\n",
        "어떻게 텍스트 데이터를 다뤄야 하는지, 텍스트를 벡터화 하는 법, 문서에서 토픽을 모델하는 법 등 다양한 NLP 기법을 배웠는데요.<br/>\n",
        "이번 스프린트 챌린지에선 [Fake/Real News Dataset](https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset)을 사용하여 배운 것들을 복습해보는 시간을 갖겠습니다.\n",
        "\n",
        "**주의 : 모델의 성능을 최대한 끌어올리는 것이 아닌 모델 구동에 초점을 맞춰주세요.<br/>\n",
        "모든 문제를 완료한 후에도 \"시간이 남았다면\" 정확도를 올리는 것에 도전하시는 것을 추천드립니다.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BCX5K0nP0ZKQ"
      },
      "outputs": [],
      "source": [
        "# 코드 실행 전 seed를 지정하겠습니다.\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C08-JiyNbdQy"
      },
      "source": [
        "## 2.0 데이터셋을 불러옵니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyndWa5hxEmk"
      },
      "source": [
        "- 위 캐글 링크에서 데이터셋을 받아 업로드 합니다.<br/>\n",
        "(직접 업로드하게 되면 시간이 꽤 걸리므로 **drive_mount** 나 **kaggle 연동**하시는 것을 추천드립니다.)\n",
        "\n",
        "- 'label' 열을 만들어 Fake = 1, True = 0 로 레이블링해줍니다.\n",
        "- 두 파일을 합쳐 하나의 데이터프레임에 저장해 준 후 데이터를 섞어줍니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gcsfs\n",
        "GCS_DS_PATH = \"gs://kds-e71c1b9b5ac29135e88e262af6c66b69ee7189c49c9966ff42373099\""
      ],
      "metadata": {
        "id": "OcKATDCbryiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "True_df = pd.read_csv(GCS_DS_PATH+'/True.csv')\n",
        "Fake_df = pd.read_csv(GCS_DS_PATH+'/Fake.csv')"
      ],
      "metadata": {
        "id": "qef3K6purjNR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "True_df.shape, Fake_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nqmAFpiuqb8",
        "outputId": "7c3fcad5-9b32-43b6-de60-70cac3451e20"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((21417, 4), (23481, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "True_df['label'] = 0\n",
        "Fake_df['label'] = 1"
      ],
      "metadata": {
        "id": "RMY0c9z9s4pQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([True_df[['text','label']],Fake_df[['text', 'label']]])"
      ],
      "metadata": {
        "id": "fP-xuRpOuEUp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "3OTylmVkum2s",
        "outputId": "bedf7eab-3dc3-46f7-c243-9498b1c35751"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9aec590d-b12a-450e-8762-a8969e3834ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23476</th>\n",
              "      <td>21st Century Wire says As 21WIRE reported earl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23477</th>\n",
              "      <td>21st Century Wire says It s a familiar theme. ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23478</th>\n",
              "      <td>Patrick Henningsen  21st Century WireRemember ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23479</th>\n",
              "      <td>21st Century Wire says Al Jazeera America will...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23480</th>\n",
              "      <td>21st Century Wire says As 21WIRE predicted in ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>44898 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9aec590d-b12a-450e-8762-a8969e3834ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9aec590d-b12a-450e-8762-a8969e3834ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9aec590d-b12a-450e-8762-a8969e3834ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                    text  label\n",
              "0      WASHINGTON (Reuters) - The head of a conservat...      0\n",
              "1      WASHINGTON (Reuters) - Transgender people will...      0\n",
              "2      WASHINGTON (Reuters) - The special counsel inv...      0\n",
              "3      WASHINGTON (Reuters) - Trump campaign adviser ...      0\n",
              "4      SEATTLE/WASHINGTON (Reuters) - President Donal...      0\n",
              "...                                                  ...    ...\n",
              "23476  21st Century Wire says As 21WIRE reported earl...      1\n",
              "23477  21st Century Wire says It s a familiar theme. ...      1\n",
              "23478  Patrick Henningsen  21st Century WireRemember ...      1\n",
              "23479  21st Century Wire says Al Jazeera America will...      1\n",
              "23480  21st Century Wire says As 21WIRE predicted in ...      1\n",
              "\n",
              "[44898 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbxEHBanUo9d"
      },
      "source": [
        "## 2.1 TF-IDF 를 활용하여 특정 뉴스와 유사한 뉴스 검색하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4R5mLMS5c2I"
      },
      "source": [
        "시간상 특별한 **전처리 없이** 아래 태스크를 수행하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2B-6Wkk5YGD"
      },
      "source": [
        "### 2.1.1 TFidfVectorizer를 사용하여 문서-단어 행렬(Document-Term Matrix) 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0Kw9OQwmUo9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "outputId": "6a9a6f53-7782-4c3d-a2b1-c6ff3a2ec36d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-914d0f1b-3581-4236-9284-ec7d83a9bb47\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clinton</th>\n",
              "      <th>donald</th>\n",
              "      <th>government</th>\n",
              "      <th>house</th>\n",
              "      <th>new</th>\n",
              "      <th>obama</th>\n",
              "      <th>people</th>\n",
              "      <th>president</th>\n",
              "      <th>republican</th>\n",
              "      <th>reuters</th>\n",
              "      <th>said</th>\n",
              "      <th>state</th>\n",
              "      <th>states</th>\n",
              "      <th>trump</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.071750</td>\n",
              "      <td>0.171626</td>\n",
              "      <td>0.515884</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.140037</td>\n",
              "      <td>0.124764</td>\n",
              "      <td>0.536731</td>\n",
              "      <td>0.065566</td>\n",
              "      <td>0.398552</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.084113</td>\n",
              "      <td>0.453636</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.071524</td>\n",
              "      <td>0.085543</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.378701</td>\n",
              "      <td>0.139597</td>\n",
              "      <td>0.310928</td>\n",
              "      <td>0.089174</td>\n",
              "      <td>0.065360</td>\n",
              "      <td>0.546287</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.646014</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.099359</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.160666</td>\n",
              "      <td>0.145057</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.116568</td>\n",
              "      <td>0.250738</td>\n",
              "      <td>0.061259</td>\n",
              "      <td>0.372373</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.847677</td>\n",
              "      <td>0.076444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.133781</td>\n",
              "      <td>0.090260</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.324489</td>\n",
              "      <td>0.292965</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.088083</td>\n",
              "      <td>0.156952</td>\n",
              "      <td>0.112534</td>\n",
              "      <td>0.164962</td>\n",
              "      <td>0.188016</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.815243</td>\n",
              "      <td>0.102927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.081392</td>\n",
              "      <td>0.292037</td>\n",
              "      <td>0.097536</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.353827</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.074377</td>\n",
              "      <td>0.395600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.190833</td>\n",
              "      <td>0.514601</td>\n",
              "      <td>0.556885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44893</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.194102</td>\n",
              "      <td>0.712426</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.311962</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.124569</td>\n",
              "      <td>0.406204</td>\n",
              "      <td>0.420635</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44894</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44895</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.494734</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.522133</td>\n",
              "      <td>0.136887</td>\n",
              "      <td>0.235476</td>\n",
              "      <td>0.059941</td>\n",
              "      <td>0.042978</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.585366</td>\n",
              "      <td>0.242465</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.039309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44896</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.704537</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.709667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44897</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.154755</td>\n",
              "      <td>0.419163</td>\n",
              "      <td>0.683768</td>\n",
              "      <td>0.126025</td>\n",
              "      <td>0.449120</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.089669</td>\n",
              "      <td>0.292398</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.147264</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>44898 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-914d0f1b-3581-4236-9284-ec7d83a9bb47')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-914d0f1b-3581-4236-9284-ec7d83a9bb47 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-914d0f1b-3581-4236-9284-ec7d83a9bb47');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        clinton    donald  government  ...    states     trump      year\n",
              "0      0.000000  0.071750    0.171626  ...  0.084113  0.453636  0.000000\n",
              "1      0.000000  0.071524    0.085543  ...  0.000000  0.646014  0.000000\n",
              "2      0.099359  0.000000    0.000000  ...  0.000000  0.847677  0.076444\n",
              "3      0.133781  0.090260    0.000000  ...  0.000000  0.815243  0.102927\n",
              "4      0.000000  0.081392    0.292037  ...  0.190833  0.514601  0.556885\n",
              "...         ...       ...         ...  ...       ...       ...       ...\n",
              "44893  0.000000  0.000000    0.000000  ...  0.420635  0.000000  0.000000\n",
              "44894  0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.000000\n",
              "44895  0.000000  0.000000    0.494734  ...  0.242465  0.000000  0.039309\n",
              "44896  0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.709667\n",
              "44897  0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.147264\n",
              "\n",
              "[44898 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# 이 곳에 답안을 작성하시길 바랍니다.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_features=15)\n",
        "dtm_tfidf = tfidf.fit_transform(df['text'])\n",
        "dtm_tfidf = pd.DataFrame(dtm_tfidf.todense(), columns=tfidf.get_feature_names())\n",
        "dtm_tfidf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeTMNUMM5WgQ"
      },
      "source": [
        "### 2.1.2 KNN 알고리즘을 사용하여 유사한 문서 검색하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYxO4HWxq2PF"
      },
      "source": [
        "- **42번 인덱스의 문서**와 가장 유사한 **5개 문서(42번 포함)의 인덱스**와 **해당 인덱스의 레이블**을 나타내주세요.\n",
        "- NN 모델의 파라미터 중 `algorithm = 'kd_tree'` 로 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8jjaQO8O6UKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02e92581-6938-415c-ed99-8a6c8ebe9f0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.        , 0.26300714, 0.26410604, 0.26441934, 0.27398822]]),\n",
              " array([[  42, 5766, 6618,    1, 1132]]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# 이 곳에 답안을 작성하시길 바랍니다.\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "nn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
        "nn.fit(dtm_tfidf)\n",
        "nn.kneighbors([dtm_tfidf.iloc[42]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghQSPbQE7P8b"
      },
      "source": [
        "## 2.2 Keras Embedding을 사용하여 분류하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEl8iU6j8I4M"
      },
      "source": [
        "### 2.2.0 데이터셋 split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5caKTRWq2PG"
      },
      "source": [
        "- Train, Test 데이터셋으로 분리(Split)하여 주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "55XSZyY_Sj54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec0a1f0d-b8a3-4bf3-82a0-46a229d499f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35918, 2), (8980, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# 이 곳에 답안을 작성하시길 바랍니다.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(df, train_size = 0.8, random_state=42)\n",
        "(train.shape, test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train['text']\n",
        "y_train = train['label']\n",
        "X_test = test['text']\n",
        "y_test = test['label']"
      ],
      "metadata": {
        "id": "j6FIeJrpw107"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1xXxSMn7fyt"
      },
      "source": [
        "### 2.2.1 단어 벡터의 평균을 이용하여 분류해보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_ZsjAVg7ndG"
      },
      "source": [
        "N422에서 했던 단어 임베딩 벡터의 평균을 사용하여 문장을 분류하는 작업을 수행해봅시다.<br/>\n",
        "인스턴스마다 텍스트 길이가 길고 시간이 오래 걸리므로 시간상 epoch 수를 **10 이하**로 하는 것을 추천드립니다.<br/>\n",
        "모델 구동이 목적이므로 임베딩 차원 수를 크지 않게(50이하)로 설정해주세요.<br/>\n",
        "**권장사항 : `max_len` 은 텍스트 길이 평균보다 높게 설정해주세요.**<br/>\n",
        "\n",
        "> **Tip : 모델이 학습하는 동안 2.2.3의 내용을 작성하면 시간을 절약할 수 있습니다.**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이 곳에 답안을 작성하시길 바랍니다\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "H2O0lt7Vyuv2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words = 1000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_encoded = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_encoded = tokenizer.texts_to_sequences(X_test)\n",
        "y_train=np.array(y_train)\n",
        "y_test=np.array(y_test)"
      ],
      "metadata": {
        "id": "sbglP3S1yr_V"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련용 리뷰의 평규 길이: {}'.format(np.mean(list(map(len, X_train)), dtype=int)))\n",
        "print('테스트용 리뷰의 평균 길이: {}'.format(np.mean(list(map(len, X_test)), dtype=int)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLLqgJ0gx_3b",
        "outputId": "c81a295b-11a5-49f8-8760-9c641c531eca"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련용 리뷰의 평규 길이: 2466\n",
            "테스트용 리뷰의 평균 길이: 2480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 3000\n",
        "X_train = pad_sequences(X_train_encoded, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test_encoded, maxlen=max_len)"
      ],
      "metadata": {
        "id": "idZXhsR9zcet"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = 32"
      ],
      "metadata": {
        "id": "iUSUvQ9Q5YAs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "dHber3qBBwOl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e02667d-5adf-434d-925d-3aa9aeda0113"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "449/449 [==============================] - 35s 76ms/step - loss: 0.6715 - acc: 0.5838 - val_loss: 0.6315 - val_acc: 0.8771\n",
            "Epoch 2/8\n",
            "449/449 [==============================] - 30s 67ms/step - loss: 0.5606 - acc: 0.8751 - val_loss: 0.4824 - val_acc: 0.9059\n",
            "Epoch 3/8\n",
            "449/449 [==============================] - 30s 68ms/step - loss: 0.4232 - acc: 0.9212 - val_loss: 0.3627 - val_acc: 0.9319\n",
            "Epoch 4/8\n",
            "449/449 [==============================] - 30s 67ms/step - loss: 0.3296 - acc: 0.9350 - val_loss: 0.2895 - val_acc: 0.9626\n",
            "Epoch 5/8\n",
            "449/449 [==============================] - 30s 66ms/step - loss: 0.2700 - acc: 0.9484 - val_loss: 0.2416 - val_acc: 0.9656\n",
            "Epoch 6/8\n",
            "449/449 [==============================] - 30s 66ms/step - loss: 0.2297 - acc: 0.9555 - val_loss: 0.2080 - val_acc: 0.9690\n",
            "Epoch 7/8\n",
            "449/449 [==============================] - 30s 68ms/step - loss: 0.1999 - acc: 0.9627 - val_loss: 0.1829 - val_acc: 0.9713\n",
            "Epoch 8/8\n",
            "449/449 [==============================] - 30s 66ms/step - loss: 0.1777 - acc: 0.9660 - val_loss: 0.1635 - val_acc: 0.9749\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ffb1ff12a10>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "model.fit(X_train, y_train, batch_size=64, epochs=8, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mskD0JAHzzEw",
        "outputId": "34866d3c-4ce2-4a2f-ce83-e5c795cd9cb0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "281/281 [==============================] - 2s 6ms/step - loss: 0.1633 - acc: 0.9748\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1632927507162094, 0.9748329520225525]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SzUwLkcAK1A"
      },
      "source": [
        "### 2.2.2 LSTM을 사용하여 텍스트 분류 수행해보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4UZ9ZqOAIjw"
      },
      "source": [
        "N423에서 했던 단어 임베딩 벡터의 평균을 사용하여 문장을 분류하는 작업을 수행해봅시다.<br/>\n",
        "인스턴스마다 텍스트 길이가 길어 시간이 매우 오래 걸리므로 <br/>\n",
        "**층을 최소한으로 쌓고**, epoch 수를 **3 이하**로 하는 것을 추천드립니다.<br/>\n",
        "\n",
        "> **Tip : 모델이 학습하는 동안 2.2.3의 내용을 작성하면 시간을 절약할 수 있습니다.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9PLNlzEVBSyE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "19095203-2b53-48c7-cec0-f59a553c7d1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/2\n",
            "249/449 [===============>..............] - ETA: 45:10 - loss: 0.2762 - acc: 0.9196"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-010eb07730b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 이 곳에 답안을 작성하시길 바랍니다\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim))\n",
        "model.add(LSTM(16, dropout=0.2, recurrent_dropout=0.2)) \n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "model.fit(X_train, y_train, batch_size=64, epochs=2, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "B3diVPyq20au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsNOs2wmBV1z"
      },
      "source": [
        "### 2.2.3 위에서 실행한 내용에 대해 다시 알아봅시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMR2t2wOEPYm"
      },
      "source": [
        "#### a) 데이터셋을 학습할 때 사용하는 `pad_sequences`  메서드에 대해 설명해주세요.<br/>어떤 기능을 하나요? 모델을 학습할 때 왜 필요한가요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7_ECWSYQ4JV"
      },
      "source": [
        "*이곳에 답안을 입력해주세요*\n",
        "\n",
        "각 문장의 길이가 서로 같을 때 기계는 하나의 행렬로 보고, 한꺼번에 병렬 연산 처리 할 수 있다. pad_sequences를 통해 이러한 문장의 길이를 맞춰주는 작업을 할 수 있다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeZ6AcloEYD5"
      },
      "source": [
        "#### b) 2.2.1과 2.2.2에서 사용한 각 모델의 evaluation 성능은 어떻게 나왔나요?<br/>각 모델의 장단점은 무엇이라고 생각하나요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SyqQzzHQ4EP"
      },
      "source": [
        "*이곳에 답안을 입력해주세요* \n",
        "\n",
        "- 단어 벡터의 평균을 이용한 분류(0.1632927507162094, 0.9748329520225525)\n",
        "- LSTM을 이용한 분류 (램 사용량 초과로 세션 다운됐습니다.)\n",
        "- 단어 벡터의 평균을 이용한 분류는 빠르다는 장점이 있고, LSTM을 이용한 분류는 연산 속도가 느리다는 단점이 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUwKojAGM82f"
      },
      "source": [
        "#### c) 종래의 RNN(Recurrent Neural Networks) 대신 LSTM(Long-Short Term Memory)을 사용하는 이유는 무엇인가요?<br/>(i.e. RNN에 비해 LSTM의 좋은 점을 설명해주세요.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6y44XfugQ_HR"
      },
      "source": [
        "*이곳에 답안을 입력해주세요*\n",
        "\n",
        "RNN에 비해 LSTM은 기울기 폭발, 기울기 소실과 장기 의존성 문제를 개선했다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J1kzTmDEaLU"
      },
      "source": [
        "#### d) LSTM이나 RNN을 사용하는 예시를 **3개**이상 제시하고 해당되는 경우에 왜 LSTM이나 RNN을 사용하는 것 적절한지 간단하게 설명해주세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck8GPjc_Q_vA"
      },
      "source": [
        "*이곳에 답안을 입력해주세요*\n",
        "\n",
        "이미지 캡셔닝, 기계번역, 비디오 프레임별 분류\n",
        "\n",
        "연속된 데이터를 처리하기 위해 고안된 신경망이기 때문이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4pP7g8DE0Cz"
      },
      "source": [
        "#### e) 이외에 N424 에서 배운 자연어처리 모델과 관련된 키워드를 3개 이상 적어주세요. <br/> (해당 키워드에 대한 설명은 옵션입니다.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-sO4mMuRAhp"
      },
      "source": [
        "*이곳에 답안을 입력해주세요*\n",
        "\n",
        "Transformer, Self-Attention, 인코더, 디코더"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRn44qjhUo9j"
      },
      "source": [
        "# Advanced Goals: 3점을 획득하기 위해선 아래의 조건 중 하나 이상을 만족해야합니다\n",
        " \n",
        "- 2.1 에서 TF-IDF(`TfidfVectorizer`)가 아닌 방법을 사용하여 유사도 검색을 수행해보세요.<br/>\n",
        "TF-IDF와 해당 방법의 차이를 설명해주세요. \n",
        "- 2.2 에서 사용한 방법을 재사용하되 하이퍼 파라미터를 조정하거나 모델 구조를 변경하여 성능을 올려봅시다.<br/>**(주의 : GridSearch, RandomSearch 등의 방법을 사용하여도 좋으나 시간이 오래 걸리므로 범위를 잘 선택해야 합니다.)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이 곳에 답안을 작성하시길 바랍니다\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "count_vect = CountVectorizer(stop_words='english', max_features=100)\n",
        "dtm_count= count_vect.fit_transform(df['text'])\n",
        "\n",
        "cosine_sim = cosine_similarity(dtm_count, dtm_count)\n",
        "print('코사인 유사도 연산 결과 :',cosine_sim.shape)"
      ],
      "metadata": {
        "id": "6BliQxZc-Jsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CountVectorizer는 TF-IDF와 달리 단순히 단어들의 빈도만 고려하여 벡터화합니다."
      ],
      "metadata": {
        "id": "Onc3_cd6_KnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "e3qSXkUx-UvU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ai08-sc42x-정석희.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernel_info": {
      "name": "u4-s1-nlp"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "nteract": {
      "version": "0.22.4"
    },
    "toc-autonumbering": false,
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}